{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b3486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d53f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words = -1):\n",
    "    if num_words > -1:\n",
    "        tokenize = tf.keras.preprocessing.text.Tokenizer(num_words = num_words)\n",
    "    else:\n",
    "        tokenize = tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenize.fit_on_texts(corpus)\n",
    "    return tokenize\n",
    "\n",
    "def create_database(dataset, column):\n",
    "    #Punctuating It\n",
    "    dataset[column] = dataset[column].str.replace('[{}]'.format(string.punctuation), '')\n",
    "    #Making It lower\n",
    "    dataset[column] = dataset[column].str.lower()\n",
    "    #Making It a one long string by cat function\n",
    "    lyrics = dataset[column].str.cat()\n",
    "    corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "    for l in range(len(corpus)):\n",
    "        corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "    corpus = [l for l in corpus if l != '']\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b93c953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('songdata.csv', dtype=str)[:250]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a0224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-4fc1b22bf2fd>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dataset[column] = dataset[column].str.replace('[{}]'.format(string.punctuation), '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "#Creating a Courpus od Dataset\n",
    "corpus = create_database(dataset, 'text')\n",
    "\n",
    "tokenizer = tokenize_corpus(corpus,num_words=2000)\n",
    "\n",
    "total_words = tokenizer.num_words\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5851143f",
   "metadata": {},
   "source": [
    "# Creating Sequences and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7b4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 802, 175, 653]\n",
      "well go on walking for hours and talking\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_seq = token_list[:i+1]\n",
    "        sequences.append(n_gram_seq)\n",
    "print(sequences[10])\n",
    "print(corpus[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df6240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   8 802\n",
      " 175 653]\n",
      "47348\n",
      "47348\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5   8 802\n",
      " 175]\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "#Padding the Sequence For equal\n",
    "\n",
    "#Getting the largest length in the sequence\n",
    "len_seq = max([len(seq) for seq in sequences])\n",
    "print(len_seq)\n",
    "\n",
    "#if we use len() we get total no of sequences\n",
    "padded_seq = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=len_seq, padding='pre')\n",
    "\n",
    "#converting the sequence into array\n",
    "array_padded_seq = np.array(padded_seq)\n",
    "print(array_padded_seq[10])\n",
    "\n",
    "print(len(array_padded_seq))\n",
    "\n",
    "#Splitting the sequences in testing and training data\n",
    "\n",
    "#Here we are splitting the last elemet of every list as labels so..\n",
    "input_seq, labels = array_padded_seq[:,:-1], array_padded_seq[:,-1]\n",
    "print(len(input_seq))\n",
    "print(input_seq[10])\n",
    "print(labels[10])\n",
    "\n",
    "#One hot encoding the labels\n",
    "encoded_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af80e30a",
   "metadata": {},
   "source": [
    "# Train a (Better) Text Generation Model\n",
    "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7106fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 19, 64)            128000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 40)                13600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              82000     \n",
      "=================================================================\n",
      "Total params: 223,600\n",
      "Trainable params: 223,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(total_words, 64, input_length=len_seq-1))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(len_seq)))\n",
    "model.add(tf.keras.layers.Dense(units = total_words, activation = 'softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8e77ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1480/1480 [==============================] - 24s 14ms/step - loss: 5.9816 - accuracy: 0.0467\n",
      "Epoch 2/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 5.6860 - accuracy: 0.0495\n",
      "Epoch 3/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 5.4947 - accuracy: 0.0643\n",
      "Epoch 4/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 5.3341 - accuracy: 0.0867\n",
      "Epoch 5/100\n",
      "1480/1480 [==============================] - 23s 15ms/step - loss: 5.1796 - accuracy: 0.1085\n",
      "Epoch 6/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 4.9956 - accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 4.8228 - accuracy: 0.1396\n",
      "Epoch 8/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 4.6667 - accuracy: 0.1584\n",
      "Epoch 9/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 4.5324 - accuracy: 0.1755\n",
      "Epoch 10/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 4.4094 - accuracy: 0.1913\n",
      "Epoch 11/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 4.2997 - accuracy: 0.2046\n",
      "Epoch 12/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 4.1972 - accuracy: 0.2183\n",
      "Epoch 13/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 4.1098 - accuracy: 0.2288\n",
      "Epoch 14/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 4.0251 - accuracy: 0.2405\n",
      "Epoch 15/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.9469 - accuracy: 0.2495\n",
      "Epoch 16/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 3.8756 - accuracy: 0.2600\n",
      "Epoch 17/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.8137 - accuracy: 0.2672\n",
      "Epoch 18/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.7484 - accuracy: 0.2747\n",
      "Epoch 19/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.6951 - accuracy: 0.2807\n",
      "Epoch 20/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.6439 - accuracy: 0.2882\n",
      "Epoch 21/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.5913 - accuracy: 0.2965\n",
      "Epoch 22/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.5456 - accuracy: 0.3040\n",
      "Epoch 23/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.5008 - accuracy: 0.3098\n",
      "Epoch 24/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.4617 - accuracy: 0.3140\n",
      "Epoch 25/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.4205 - accuracy: 0.3205\n",
      "Epoch 26/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.3824 - accuracy: 0.3261\n",
      "Epoch 27/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 3.3472 - accuracy: 0.3305\n",
      "Epoch 28/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.3164 - accuracy: 0.3350\n",
      "Epoch 29/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.2804 - accuracy: 0.3412\n",
      "Epoch 30/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.2509 - accuracy: 0.3448\n",
      "Epoch 31/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.2257 - accuracy: 0.3489\n",
      "Epoch 32/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.1968 - accuracy: 0.3533\n",
      "Epoch 33/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.1739 - accuracy: 0.3559\n",
      "Epoch 34/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.1397 - accuracy: 0.3625\n",
      "Epoch 35/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.1179 - accuracy: 0.3660\n",
      "Epoch 36/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.0924 - accuracy: 0.3698\n",
      "Epoch 37/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.0773 - accuracy: 0.3715\n",
      "Epoch 38/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.0484 - accuracy: 0.3760\n",
      "Epoch 39/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 3.0304 - accuracy: 0.3781\n",
      "Epoch 40/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 3.0051 - accuracy: 0.3827\n",
      "Epoch 41/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9866 - accuracy: 0.3866\n",
      "Epoch 42/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9784 - accuracy: 0.3869\n",
      "Epoch 43/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9457 - accuracy: 0.3944\n",
      "Epoch 44/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9325 - accuracy: 0.3973\n",
      "Epoch 45/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9380 - accuracy: 0.3937\n",
      "Epoch 46/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.9027 - accuracy: 0.4008\n",
      "Epoch 47/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.8871 - accuracy: 0.4026\n",
      "Epoch 48/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.8712 - accuracy: 0.4047\n",
      "Epoch 49/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.8539 - accuracy: 0.4090\n",
      "Epoch 50/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 2.8431 - accuracy: 0.4107\n",
      "Epoch 51/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 2.8222 - accuracy: 0.4136\n",
      "Epoch 52/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.8277 - accuracy: 0.4139\n",
      "Epoch 53/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.8001 - accuracy: 0.4173\n",
      "Epoch 54/100\n",
      "1480/1480 [==============================] - 20s 13ms/step - loss: 2.7821 - accuracy: 0.4200\n",
      "Epoch 55/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7692 - accuracy: 0.4249\n",
      "Epoch 56/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7589 - accuracy: 0.4271\n",
      "Epoch 57/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7513 - accuracy: 0.4275\n",
      "Epoch 58/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7237 - accuracy: 0.4314\n",
      "Epoch 59/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7222 - accuracy: 0.4305\n",
      "Epoch 60/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.7067 - accuracy: 0.4347\n",
      "Epoch 61/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6945 - accuracy: 0.4352\n",
      "Epoch 62/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6827 - accuracy: 0.4389\n",
      "Epoch 63/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6673 - accuracy: 0.4409\n",
      "Epoch 64/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6643 - accuracy: 0.4408\n",
      "Epoch 65/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6600 - accuracy: 0.4419\n",
      "Epoch 66/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6544 - accuracy: 0.4418\n",
      "Epoch 67/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6258 - accuracy: 0.4475\n",
      "Epoch 68/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6141 - accuracy: 0.4503\n",
      "Epoch 69/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6176 - accuracy: 0.4505\n",
      "Epoch 70/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6099 - accuracy: 0.4493\n",
      "Epoch 71/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5944 - accuracy: 0.4523\n",
      "Epoch 72/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5839 - accuracy: 0.4548\n",
      "Epoch 73/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5805 - accuracy: 0.4547\n",
      "Epoch 74/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5753 - accuracy: 0.4556\n",
      "Epoch 75/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5738 - accuracy: 0.4563\n",
      "Epoch 76/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5457 - accuracy: 0.4617\n",
      "Epoch 77/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5386 - accuracy: 0.4629\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5216 - accuracy: 0.4662\n",
      "Epoch 79/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5209 - accuracy: 0.4649\n",
      "Epoch 80/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5137 - accuracy: 0.4675\n",
      "Epoch 81/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5102 - accuracy: 0.4673\n",
      "Epoch 82/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5056 - accuracy: 0.4673\n",
      "Epoch 83/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4880 - accuracy: 0.4722\n",
      "Epoch 84/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4814 - accuracy: 0.4718\n",
      "Epoch 85/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4997 - accuracy: 0.4691\n",
      "Epoch 86/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4798 - accuracy: 0.4740\n",
      "Epoch 87/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4617 - accuracy: 0.4768\n",
      "Epoch 88/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4536 - accuracy: 0.4773\n",
      "Epoch 89/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4410 - accuracy: 0.4807\n",
      "Epoch 90/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4374 - accuracy: 0.4804\n",
      "Epoch 91/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4324 - accuracy: 0.4818\n",
      "Epoch 92/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4345 - accuracy: 0.4803\n",
      "Epoch 93/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4081 - accuracy: 0.4842\n",
      "Epoch 94/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4139 - accuracy: 0.4844\n",
      "Epoch 95/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3960 - accuracy: 0.4887\n",
      "Epoch 96/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3909 - accuracy: 0.4890\n",
      "Epoch 97/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3986 - accuracy: 0.4869\n",
      "Epoch 98/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3809 - accuracy: 0.4896\n",
      "Epoch 99/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3822 - accuracy: 0.4900\n",
      "Epoch 100/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3636 - accuracy: 0.4952\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model\n",
    "history = model.fit(input_seq, encoded_labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dee4e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83edf80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills on the middle of the line that life before you feel toys toys toys toys in the middle in the middle through the money men if spend place in this nights voulezvous of us last ease me this peaceful place of this nights men can move yeah yeah yeah yeah yeah yeah jack jeanie jeanie jeanie jeanie with someone so bad goin weak in the time baby you yet fly up and girl be a chance to the lot of a road star in the world where you ya ya ya ya flown wants this days well needs christmas out\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=len_seq-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7e3ff",
   "metadata": {},
   "source": [
    "# Varying the Possible Outputs\n",
    "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output?\n",
    "\n",
    "Switching from model.predict_classes to model.predict_proba will get us all of the class probabilities. We can combine this with np.random.choice to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "627ccc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# Test the method with just the first word after the seed text\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=len_seq-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
    "                             p=predicted_probs)\n",
    "# Running this cell multiple times should get you some variance in output\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff691e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chutiya Kaliyaan We live in a dancing sea chill first town old fashioned paper true still shadows from cold fine unreal promises yeah forever sharing angels now talked laughter a little beginning singing whoever she get em sharing myself myself train wrong rikky told him easy more things shes goin round loud for insane in us apart between your heart from side side machine comin done by the trick to me weve done that whats the heat stays his new laughed will die twice the sunrise side of living side of love among too jump theyre happens she tasted did you surrender get\n"
     ]
    }
   ],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"Chutiya Kaliyaan We\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=len_seq-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list)[0]\n",
    "    predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec8319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
