{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3546cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c65065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23262\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "(train_examples, valid_examples, test_examples), info = tfds.load('cats_vs_dogs',split=['train[80%:]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True, \n",
    "    as_supervised=True )\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    "print(num_examples)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a828f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the image\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (224,224))/255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dec25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46943153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation\n",
    "#Shuffling, resizing etc batches of images\n",
    "train_data = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "valid_data = valid_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_data = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744645a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.25390384 0.24606068 0.24998225]\n",
      "  [0.25490198 0.24705882 0.2509804 ]\n",
      "  [0.25892973 0.2510866  0.25500816]\n",
      "  ...\n",
      "  [0.47583157 0.4954394  0.5072041 ]\n",
      "  [0.46798843 0.48759627 0.49936098]\n",
      "  [0.46798843 0.48759627 0.49936098]]\n",
      "\n",
      " [[0.25490198 0.24705882 0.2509804 ]\n",
      "  [0.25823492 0.25039178 0.25431335]\n",
      "  [0.2627451  0.25490198 0.25882354]\n",
      "  ...\n",
      "  [0.47847515 0.498083   0.50984764]\n",
      "  [0.47063202 0.49023986 0.5020045 ]\n",
      "  [0.47063202 0.49023986 0.5020045 ]]\n",
      "\n",
      " [[0.25758928 0.24974614 0.2536677 ]\n",
      "  [0.26110294 0.2532598  0.25718138]\n",
      "  [0.26296106 0.25511792 0.2590395 ]\n",
      "  ...\n",
      "  [0.48504025 0.50464815 0.51641285]\n",
      "  [0.4771971  0.49680495 0.5085697 ]\n",
      "  [0.4771971  0.49680495 0.5085697 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  ...\n",
      "  [0.23570842 0.20104451 0.18049134]\n",
      "  [0.2220639  0.19461292 0.16324036]\n",
      "  [0.26738426 0.23993327 0.20856072]]\n",
      "\n",
      " [[0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  ...\n",
      "  [0.23592433 0.20126043 0.18070726]\n",
      "  [0.21122637 0.1837754  0.15240283]\n",
      "  [0.23187149 0.2044205  0.17304794]]\n",
      "\n",
      " [[0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  [0.00784314 0.00784314 0.00784314]\n",
      "  ...\n",
      "  [0.23300937 0.19834547 0.1777923 ]\n",
      "  [0.20925245 0.18180147 0.15042892]\n",
      "  [0.23132956 0.20387858 0.17250602]]], shape=(224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_data.take(1):\n",
    "    pass\n",
    "image_batch.shape\n",
    "print(image_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7983ab",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "All it takes is to put a linear classifier on top of the feature_extractor_layer with the Hub module.\n",
    "\n",
    "For speed, we start out with a non-trainable feature_extractor_layer, but you can also enable fine-tuning for greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b97086",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fine_tuning = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a202217",
   "metadata": {},
   "source": [
    "# Load TFHub Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7387bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
     ]
    }
   ],
   "source": [
    "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(\"Using {} with input size {} and output dimension {}\".format(\n",
    "  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5961078",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dbe614084397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMODULE_HANDLE\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_base\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m feature_extractor = hub.keras_layer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,), \n\u001b[0m\u001b[0;32m      3\u001b[0m                                    \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFV_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                    trainable=do_fine_tuning)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
    "feature_extractor = hub.keras_layer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,), \n",
    "                                   output_shape=[FV_SIZE],\n",
    "                                   trainable=do_fine_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e4b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
