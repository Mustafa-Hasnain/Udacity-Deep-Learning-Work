{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51798210",
   "metadata": {},
   "source": [
    "In this tutorial, we will discuss how to classify images into pictures of cats or pictures of dogs. We'll build an image classifier using tf.keras.Sequential model and load data using tf.keras.preprocessing.image.ImageDataGenerator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f9d91b",
   "metadata": {},
   "source": [
    "# Specific concepts that will be covered:\n",
    "In the process, we will build practical experience and develop intuition around the following concepts\n",
    "\n",
    "Building data input pipelines using the tf.keras.preprocessing.image.ImageDataGenerator class — How can we efficiently work with data on disk to interface with our model?\n",
    "Overfitting - what is it, how to identify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ec4a1",
   "metadata": {},
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "os — to read files and directory structure\n",
    "\n",
    "numpy — for some matrix math outside of TensorFlow\n",
    "\n",
    "matplotlib.pyplot — to plot the graph and display images in our training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d86834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f75895",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "To build our image classifier, we begin by downloading the dataset. The dataset we are using is a filtered version of Dogs vs. Cats dataset from Kaggle (ultimately, this dataset is provided by Microsoft Research).\n",
    "\n",
    "In previous Colabs, we've used TensorFlow Datasets, which is a very easy and convenient way to use datasets. In this Colab however, we will make use of the class tf.keras.preprocessing.image.ImageDataGenerator which will read data from disk. We therefore need to directly download Dogs vs. Cats from a URL and unzip it to the Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dccbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\n",
      "C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\\cats_and_dogs_filtered\n"
     ]
    }
   ],
   "source": [
    "#_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "dir_path = os.path.join(path, \"cats_and_dogs_filtered\")\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a436eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Containing tain dataset for cats and dogs: \n",
      " C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\\cats_and_dogs_filtered\\train\\cats \n",
      " C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\\cats_and_dogs_filtered\\train\\dogs\n",
      "Directory Containing Validation dataset for cats and dogs: \n",
      " C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\\cats_and_dogs_filtered\\validation\\cats \n",
      " C:\\Users\\Mustafa Hasnain\\Desktop\\Udacity Introduction to TensorFlow- Deep Learning\\cats_and_dogs_filtered\\validation\\dogs\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dir_path, \"train\")\n",
    "validation_path = os.path.join(dir_path, \"validation\")\n",
    "train_cats_path = os.path.join(train_path, \"cats\")\n",
    "train_dogs_path = os.path.join(train_path, \"dogs\")\n",
    "validation_cats_path = os.path.join(validation_path, \"cats\")\n",
    "validation_dogs_path = os.path.join(validation_path, \"dogs\")\n",
    "print(\"Directory Containing tain dataset for cats and dogs: \\n\",train_cats_path, \"\\n\",train_dogs_path)\n",
    "print(\"Directory Containing Validation dataset for cats and dogs: \\n\",validation_cats_path, \"\\n\",validation_dogs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169c3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or another method to deownload and get path of dataset is: \n",
    "#_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "#zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
    "#zip_dir_base = os.path.dirname(zip_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72da49",
   "metadata": {},
   "source": [
    "# Understanding Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344f42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The No of files in Train-Cats Directory:  1000\n",
      "The No of files in Train-Dogs Directory:  1000\n",
      "The No of files in Validation-Cats Directory:  500\n",
      "The No of files in Validation-Dogs Directory:  500\n"
     ]
    }
   ],
   "source": [
    "num_cats_tr = os.listdir(train_cats_path) #os.Listdir returns the files in the path given/directory\n",
    "num_dogs_tr = os.listdir(train_dogs_path)\n",
    "num_cats_val = os.listdir(validation_cats_path)\n",
    "num_dogs_val = os.listdir(validation_dogs_path)\n",
    "print(\"The No of files in Train-Cats Directory: \",len(num_cats_tr))\n",
    "print(\"The No of files in Train-Dogs Directory: \",len(num_dogs_tr))\n",
    "print(\"The No of files in Validation-Cats Directory: \",len(num_cats_val))\n",
    "print(\"The No of files in Validation-Dogs Directory: \",len(num_cats_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18078557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Images in Train:  2000\n",
      "Total Number of Images in Validation:  1000\n"
     ]
    }
   ],
   "source": [
    "total_train = len(num_cats_tr + num_dogs_tr)\n",
    "total_val = len(num_cats_val+ num_dogs_val)\n",
    "print(\"Total Number of Images in Train: \", total_train)\n",
    "print(\"Total Number of Images in Validation: \", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055e5a6",
   "metadata": {},
   "source": [
    "# Setting Model Parameters\n",
    "For convenience, we'll set up variables that will be used later while pre-processing our dataset and training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb582ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100 # Number of training examples to process before updating our models variables\n",
    "IMG_SHAPE = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803e4d3",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n",
    "\n",
    "Read images from the disk\n",
    "Decode contents of these images and convert it into proper grid format as per their RGB content\n",
    "Convert them into floating point tensors\n",
    "Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "Fortunately, all these tasks can be done using the class tf.keras.preprocessing.image.ImageDataGenerator.\n",
    "\n",
    "We can set this up in a couple of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61994394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "validation_img_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea303e",
   "metadata": {},
   "source": [
    "After defining our generators for training and validation images, flow_from_directory method will load images from the disk, apply rescaling, and resize them using single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11534118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_img_generator.flow_from_directory(directory=train_path, batch_size=BATCH_SIZE, shuffle=True,class_mode='binary',target_size = (IMG_SHAPE,IMG_SHAPE))\n",
    "val_data_gen = validation_img_generator.flow_from_directory(directory=validation_path, batch_size=BATCH_SIZE, shuffle=False,class_mode='binary',target_size = (IMG_SHAPE,IMG_SHAPE))\n",
    "#target_size = (150,150) px\n",
    "#In Validation and Test Data Shuffling is mostly likely False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a5b6831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_gen.image_shape)\n",
    "print(val_data_gen.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64969a8a",
   "metadata": {},
   "source": [
    "# Visualizing Training images\n",
    "We can visualize our training images by getting a batch of images from the training generator, and then plotting a few of them using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1104c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images,_ = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc84b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1a0088a29046>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_images' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_image(img_list):\n",
    "    fig, axes = plt.subplots(1,5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(img_list, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_image(sample_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a7715",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "Define the model\n",
    "The model consists of four convolution blocks with a max pool layer in each of them. Then we have a fully connected layer with 512 units, with a relu activation function. The model will output class probabilities for two classes — dogs and cats — using softmax.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4144ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150,150,3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units = 512, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(units = 2))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c120a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,453,634\n",
      "Trainable params: 3,453,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69065d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mustafa Hasnain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 65s 3s/step - loss: 0.7568 - accuracy: 0.4875 - val_loss: 0.6929 - val_accuracy: 0.5010\n",
      "Epoch 2/10\n",
      "13/20 [==================>...........] - ETA: 19s - loss: 0.6928 - accuracy: 0.4915"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "#Train model\n",
    "history = model.fit_generator(train_data_gen, steps_per_epoch = math.ceil(total_train/BATCH_SIZE), epochs=EPOCHS, validation_data=val_data_gen, validation_steps=np.ceil(total_val/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f77f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
